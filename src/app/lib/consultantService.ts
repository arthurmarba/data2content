/**
 * @fileoverview Servi√ßo principal para obter respostas do consultor Tuca.
 * Vers√£o otimizada para buscar m√©tricas proativamente e envi√°-las no contexto inicial do LLM.
 * Timeout de leitura do stream aumentado.
 * Adiciona mensagem inicial de processamento din√¢mica baseada na inten√ß√£o detectada.
 * Limita o hist√≥rico enviado ao LLM para acelerar o processamento.
 * @version 4.3.5
 */

import { logger } from '@/app/lib/logger';
import { normalizeText, determineIntent, getRandomGreeting, IntentResult, DeterminedIntent } from './intentService';
import { askLLMWithEnrichedContext } from './aiOrchestrator';
import * as stateService from '@/app/lib/stateService';
import * as dataService from './dataService';
import { UserNotFoundError } from '@/app/lib/errors';
import { IUser } from '@/app/models/User';
import { ChatCompletionMessageParam } from 'openai/resources/chat/completions';
import { AggregatedReport } from './reportHelpers';
import { sendWhatsAppMessage } from '@/app/lib/whatsappService';

// Configura√ß√µes
const CACHE_TTL_SECONDS = Number(process.env.CACHE_TTL_SECONDS) || 60 * 5;
const STREAM_READ_TIMEOUT_MS = Number(process.env.STREAM_READ_TIMEOUT_MS) || 90_000;
const HISTORY_LIMIT = Number(process.env.LLM_HISTORY_LIMIT) || 10; // *** NOVO: Limite de mensagens no hist√≥rico ***

/**
 * @interface EnrichedContext
 * @description Define a estrutura do contexto enviado ao LLM, incluindo dados do usu√°rio e m√©tricas.
 */
interface EnrichedContext {
    user: IUser;
    historyMessages: ChatCompletionMessageParam[]; // Este ser√° o hist√≥rico limitado
    dialogueState?: stateService.DialogueState;
    latestReport?: AggregatedReport | null;
}

/**
 * Obt√©m a resposta do consultor Tuca para uma mensagem recebida.
 * Busca proativamente o √∫ltimo relat√≥rio de m√©tricas do usu√°rio.
 * @param {string} fromPhone N√∫mero de telefone do remetente.
 * @param {string} incoming Mensagem recebida do usu√°rio.
 * @returns {Promise<string>} A resposta do consultor.
 */
export async function getConsultantResponse(
    fromPhone: string,
    incoming: string
): Promise<string> {
    // Define uma TAG mais espec√≠fica para esta vers√£o
    const TAG = '[consultantService 4.3.5]'; // Vers√£o atualizada
    const start = Date.now();
    const rawText = incoming;
    logger.info(`${TAG} ‚á¢ ${fromPhone.slice(-4)}‚Ä¶ ¬´${rawText.slice(0, 40)}¬ª`);

    // --- 0. Normaliza√ß√£o ---
    const norm = normalizeText(rawText.trim());
    if (!norm) {
        logger.warn(`${TAG} Mensagem normalizada vazia.`);
        return `${getRandomGreeting('')} Pode repetir, por favor? N√£o entendi bem.`;
    }

    // --- 1. Carregar Dados do Usu√°rio ---
    let user: IUser;
    try {
        user = await dataService.lookupUser(fromPhone);
        logger.debug(`${TAG} Usu√°rio ${user._id} carregado.`);
    } catch (e) {
        logger.error(`${TAG} Erro em lookupUser:`, e);
        if (e instanceof UserNotFoundError) {
            return 'Ol√°! Parece que √© nosso primeiro contato por aqui. Para come√ßar, preciso fazer seu cadastro r√°pido. Pode me confirmar seu nome completo, por favor?';
        }
        return 'Tive um problema ao buscar seus dados. Poderia tentar novamente em alguns instantes? Se persistir, fale com o suporte. üôè';
    }
    const uid = user._id.toString();
    const userName = user.name || 'criador';
    const greeting = getRandomGreeting(userName);

    // --- 1.5 Verificar Cache (Ap√≥s ter o usu√°rio para a chave) ---
    const cacheKey = `resp:${fromPhone}:${norm.slice(0, 100)}`;
    try {
        const cached = await stateService.getFromCache(cacheKey);
        if (cached) {
            logger.info(`${TAG} (cache hit) ${Date.now() - start} ms`);
            return cached;
        }
        logger.info(`${TAG} (cache miss)`);
    } catch (cacheError) {
        logger.error(`${TAG} Erro ao buscar do cache Redis:`, cacheError);
    }

    // --- 2. Carregar Contexto da Conversa (Estado) ---
    let dialogueState: stateService.DialogueState = {};
    try {
        dialogueState = await stateService.getDialogueState(uid);
        logger.debug(`${TAG} Estado carregado.`);
    } catch (stateError) {
        logger.error(`${TAG} Erro ao buscar estado do Redis:`, stateError);
    }

    // --- 2.5 Determinar Inten√ß√£o e Lidar com Casos Especiais ---
    let intentResult: IntentResult;
    let determinedIntent: DeterminedIntent | null = null;
    try {
        intentResult = await determineIntent(norm, user, rawText, dialogueState, greeting, uid);

        if (intentResult.type === 'special_handled') {
            logger.info(`${TAG} Inten√ß√£o tratada como caso especial: ${intentResult.response.slice(0, 50)}...`);
            await sendWhatsAppMessage(fromPhone, intentResult.response);
            return intentResult.response;
        } else {
            determinedIntent = intentResult.intent;
            logger.info(`${TAG} Inten√ß√£o determinada: ${determinedIntent}`);
        }

    } catch (intentError) {
        logger.error(`${TAG} Erro ao determinar inten√ß√£o:`, intentError);
        determinedIntent = 'general';
    }
    // -----------------------------------------------------------

    // --- 3. Carregar Hist√≥rico ---
    let historyString: string = '';
    try {
        historyString = await stateService.getConversationHistory(uid);
        logger.debug(`${TAG} Hist√≥rico bruto tem ${historyString.length} chars.`);
    } catch (histError) {
        logger.error(`${TAG} Erro ao buscar hist√≥rico do Redis:`, histError);
    }

    // --- 3.5 Preparar Hist√≥rico de Mensagens para o LLM (COM LIMITE) ---
    let historyMessages: ChatCompletionMessageParam[] = []; // Hist√≥rico completo parseado
    if (historyString) {
        try {
            const lines = historyString.trim().split('\n');
            let currentRole: 'user' | 'assistant' | null = null;
            let currentContent = '';
            for (const line of lines) {
                if (line.startsWith('User: ')) {
                    if (currentRole) historyMessages.push({ role: currentRole, content: currentContent.trim() });
                    currentRole = 'user';
                    currentContent = line.substring(6);
                } else if (line.startsWith('Assistant: ')) {
                    if (currentRole) historyMessages.push({ role: currentRole, content: currentContent.trim() });
                    currentRole = 'assistant';
                    currentContent = line.substring(11);
                } else if (currentRole) {
                    currentContent += '\n' + line;
                }
            }
            if (currentRole) historyMessages.push({ role: currentRole, content: currentContent.trim() });
            logger.debug(`${TAG} Hist√≥rico completo convertido para ${historyMessages.length} mensagens.`);
        } catch (parseError) {
            logger.error(`${TAG} Erro ao parsear hist√≥rico:`, parseError);
            historyMessages.length = 0;
        }
    }
    // *** NOVO: Aplica o limite ao hist√≥rico ***
    const limitedHistoryMessages = historyMessages.slice(-HISTORY_LIMIT);
    if (historyMessages.length > HISTORY_LIMIT) {
        logger.debug(`${TAG} Hist√≥rico limitado a ${HISTORY_LIMIT} mensagens (original: ${historyMessages.length}).`);
    }
    // -----------------------------------------


    // --- 4. Carregar Dados de M√©tricas (Relat√≥rio Agregado) ---
    let latestReport: AggregatedReport | null = null;
    try {
        latestReport = await dataService.getLatestAggregatedReport(uid);
        if (latestReport) {
            logger.debug(`${TAG} Relat√≥rio agregado carregado (Overall Stats: ${!!latestReport.overallStats}).`);
        } else {
            logger.info(`${TAG} Nenhum relat√≥rio agregado recente encontrado para o usu√°rio ${uid}.`);
        }
    } catch (reportError) {
        logger.error(`${TAG} Erro ao buscar relat√≥rio agregado:`, reportError);
    }

    // --- 5. Preparar Contexto Enriquecido para o LLM ---
    const enrichedContext: EnrichedContext = {
        user: user,
        historyMessages: limitedHistoryMessages, // *** USA O HIST√ìRICO LIMITADO ***
        dialogueState: dialogueState,
        latestReport: latestReport,
    };

    // --- 5.5 ENVIAR MENSAGEM INICIAL DE PROCESSAMENTO (BASEADA NA INTEN√á√ÉO) ---
    try {
        let processingMessage = `Ok, ${userName}! Recebi seu pedido. üëç\nEstou a analisar as informa√ß√µes e j√° te trago os insights...`; // Default
        switch (determinedIntent) {
            case 'script_request':
                processingMessage = `Ok, ${userName}! Pedido de roteiro recebido. üëç\nEstou a estruturar as ideias e j√° te mando o script...`;
                break;
            case 'content_plan':
                processingMessage = `Ok, ${userName}! Recebi seu pedido de plano de conte√∫do. üëç\nEstou a organizar a agenda e j√° te apresento o planejamento...`;
                break;
            case 'ranking_request':
                processingMessage = `Entendido, ${userName}! Voc√™ quer um ranking. üëç\nEstou a comparar os dados e j√° te mostro os resultados ordenados...`;
                break;
            case 'report':
            case 'ASK_BEST_PERFORMER':
            case 'ASK_BEST_TIME':
                processingMessage = `Certo, ${userName}! Recebi seu pedido de an√°lise/relat√≥rio. üëç\nEstou a compilar os dados e j√° te apresento os resultados...`;
                break;
            case 'content_ideas':
                processingMessage = `Legal, ${userName}! Buscando ideias de conte√∫do para voc√™. üëç\nEstou a verificar as tend√™ncias e j√° te trago algumas sugest√µes...`;
                break;
            case 'general':
            default:
                processingMessage = `Ok, ${userName}! Recebi sua mensagem. üëç\nEstou a processar e j√° te respondo...`;
                break;
        }
        logger.debug(`${TAG} Enviando mensagem de processamento (inten√ß√£o: ${determinedIntent}) para ${fromPhone}...`);
        await sendWhatsAppMessage(fromPhone, processingMessage);
    } catch (sendError) {
        logger.error(`${TAG} Falha ao enviar mensagem inicial de processamento (n√£o fatal):`, sendError);
    }
    // ----------------------------------------------------

    // --- 6. Chamar o LLM com o Contexto Enriquecido e Processar Resposta ---
    let finalText = '';
    let historyFromLLM: ChatCompletionMessageParam[] = [];
    let readCounter = 0;
    let streamTimeout: NodeJS.Timeout | null = null;
    let reader: ReadableStreamDefaultReader<string> | null = null;

    try {
        logger.debug(`${TAG} Chamando askLLMWithEnrichedContext com hist√≥rico limitado (${limitedHistoryMessages.length} msgs)...`); // Log atualizado
        const { stream, history: updatedHistory } = await askLLMWithEnrichedContext(
            enrichedContext, // Passa o contexto com hist√≥rico limitado
            rawText // Passa o texto original aqui
        );
        historyFromLLM = updatedHistory; // Este hist√≥rico retornado pelo orchestrator PODE ser diferente do limitado enviado
        logger.debug(`${TAG} askLLMWithEnrichedContext retornou. Iniciando leitura do stream...`);

        reader = stream.getReader();

        streamTimeout = setTimeout(() => {
            logger.warn(`${TAG} Timeout (${STREAM_READ_TIMEOUT_MS}ms) durante leitura do stream. Cancelando reader.`);
            streamTimeout = null;
            reader?.cancel(`Stream reading timeout after ${STREAM_READ_TIMEOUT_MS}ms`)
                  .catch(e => logger.error(`${TAG} Erro ao cancelar reader no timeout:`, e));
        }, STREAM_READ_TIMEOUT_MS);

        while (true) {
            // (Loop de leitura do stream mantido como est√°)
            readCounter++;
            let value: string | undefined;
            let done: boolean | undefined;

            try {
                const result = await reader.read();
                if (streamTimeout === null && !result.done) {
                    logger.warn(`${TAG} [Leitura ${readCounter}] Leitura retornou ap√≥s timeout/cancelamento, ignorando chunk.`);
                    continue;
                }
                value = result.value;
                done = result.done;

            } catch (readError: any) {
                logger.error(`${TAG} [Leitura ${readCounter}] Erro em reader.read(): ${readError.message}`);
                if (streamTimeout) clearTimeout(streamTimeout);
                streamTimeout = null;
                throw new Error(`Erro ao ler stream: ${readError.message}`);
            }

            if (done) {
                logger.debug(`${TAG} [Leitura ${readCounter}] Stream finalizado (done=true).`);
                break;
            }

            if (typeof value === 'string') {
                finalText += value;
            } else {
                logger.warn(`${TAG} [Leitura ${readCounter}] Recebido 'value' undefined, mas 'done' √© false.`);
            }
        }

        if (streamTimeout) {
            clearTimeout(streamTimeout);
            logger.debug(`${TAG} Leitura do stream conclu√≠da antes do timeout.`);
        }

        logger.debug(`${TAG} Texto final montado: ${finalText.length} chars.`);

        if (finalText.trim().length === 0) {
            logger.warn(`${TAG} Stream finalizado mas finalText est√° vazio ap√≥s ${readCounter} leituras.`);
            return 'Hum... tive um problema ao gerar a resposta final. Pode tentar de novo ou reformular seu pedido?';
        }

    } catch (err: any) {
        logger.error(`${TAG} Erro durante chamada ao LLM ou leitura do stream (ap√≥s ${readCounter} leituras):`, err);
        if (streamTimeout) clearTimeout(streamTimeout);
        streamTimeout = null;
        return 'Ops! Tive uma dificuldade t√©cnica aqui ao gerar a resposta final. Poderia tentar sua pergunta novamente em alguns instantes? üôè';
    } finally {
        if (reader) {
            try {
                await reader.releaseLock();
            } catch (releaseError) {
                logger.error(`${TAG} Erro (n√£o fatal) ao liberar reader lock no finally:`, releaseError);
            }
        }
    }

    // --- 7. Persist√™ncia P√≥s-Resposta ---
    try {
        logger.debug(`${TAG} Iniciando persist√™ncia no Redis...`);
        const nextState = { ...(dialogueState || {}), lastInteraction: Date.now() };

        // *** IMPORTANTE: Persistir o hist√≥rico COMPLETO ou o LIMITADO? ***
        // Atualmente, historyFromLLM cont√©m o hist√≥rico que o orchestrator usou/retornou.
        // Se voc√™ quiser salvar o hist√≥rico COMPLETO no Redis (recomendado para manter o contexto real),
        // voc√™ precisaria reconstru√≠-lo adicionando a √∫ltima intera√ß√£o (rawText + finalText) ao hist√≥rico
        // completo original (historyMessages) antes de limitar.
        // Por simplicidade AGORA, vamos salvar o que o orchestrator retornou (historyFromLLM),
        // mas esteja ciente que isso pode n√£o representar o hist√≥rico completo real da conversa no Redis.
        // Para salvar o hist√≥rico completo REAL, a l√≥gica aqui precisaria ser mais elaborada.

        const newHistoryString = historyFromLLM // Usando o hist√≥rico retornado pelo orchestrator
            .filter(msg => msg.role === 'user' || (msg.role === 'assistant' && typeof msg.content === 'string' && msg.content.trim().length > 0))
            .map(msg => {
                const rolePrefix = msg.role === 'user' ? 'User' : 'Assistant';
                const content = typeof msg.content === 'string' ? msg.content : JSON.stringify(msg.content);
                return `${rolePrefix}: ${content}`;
            })
            .join('\n');

        await Promise.allSettled([
            stateService.updateDialogueState(uid, nextState),
            stateService.setConversationHistory(uid, newHistoryString), // Salva o hist√≥rico usado/retornado pelo LLM
            stateService.setInCache(cacheKey, finalText, CACHE_TTL_SECONDS),
            stateService.incrementUsageCounter(uid),
        ]);
        logger.debug(`${TAG} Persist√™ncia no Redis conclu√≠da (hist√≥rico salvo: ${historyFromLLM.length} msgs).`);
    } catch (persistError) {
        logger.error(`${TAG} Erro durante a persist√™ncia no Redis (n√£o fatal):`, persistError);
    }

    // --- Finaliza√ß√£o ---
    const duration = Date.now() - start;
    logger.info(`${TAG} ‚úì ok ${duration} ms. Retornando ${finalText.length} chars.`);
    return finalText;
}


// ----- Fun√ß√£o de Resumo Semanal (Opcional) -----
// (Mantida como est√°)
/**
 * Gera um resumo estrat√©gico semanal baseado em um relat√≥rio agregado.
 * @param {string} userName Nome do usu√°rio.
 * @param {AggregatedReport} report O relat√≥rio agregado.
 * @returns {Promise<string>} O resumo gerado pela IA.
 */
export async function generateStrategicWeeklySummary(
  userName: string,
  report: AggregatedReport
): Promise<string> {
  const TAG = '[weeklySummary]';
  if (!report?.overallStats) {
      logger.warn(`${TAG} OverallStats ausente no relat√≥rio para ${userName}.`);
      return 'N√£o foi poss√≠vel gerar o resumo semanal: dados insuficientes no relat√≥rio.';
  }

  const PROMPT = `Como consultor estrat√©gico, resuma em 3 bullets concisos os principais destaques (positivos ou pontos de aten√ß√£o) das m√©tricas gerais de ${userName} desta semana, baseado nestes dados: ${JSON.stringify(
    report.overallStats
  )}. Foco em insights acion√°veis.`;

  try {
    // Substitua 'callOpenAIForQuestion' pela sua fun√ß√£o real de chamada direta √† IA.
    // return await callOpenAIForQuestion(PROMPT); // Descomente e ajuste se necess√°rio
    logger.warn(`${TAG} Chamada direta √† IA para resumo n√£o implementada/configurada.`);
    return `Resumo semanal para ${userName} (simulado): [Insight 1 baseado em ${Object.keys(report.overallStats)[0]}], [Insight 2 baseado em ${Object.keys(report.overallStats)[1]}], [Insight 3 baseado em ${Object.keys(report.overallStats)[2]}]`; // Placeholder
  } catch (e) {
    logger.error(`${TAG} Erro ao gerar resumo semanal para ${userName}:`, e);
    return `N√£o consegui gerar o resumo semanal para ${userName} agora devido a um erro.`;
  }
}
